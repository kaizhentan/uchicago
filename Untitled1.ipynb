{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruce\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\bruce\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, feature_selection,ensemble, linear_model, cross_validation, decomposition, cluster,model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruce\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\bruce\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame.from_csv('stock_data/factor_data.csv',index_col=10)\n",
    "df2 = pd.DataFrame.from_csv('stock_data/ticker_data.csv',index_col=['timestep','ticker'])\n",
    "df2 = df2.unstack()\n",
    "df2 = df2.fillna(0)\n",
    "clean_upcols = {'industry':{'TECH':0,'AGRICULTURE':1,'FINANCE':2,'CONSUMER':3,'OTHER':4}}\n",
    "df2.replace(clean_upcols,inplace=True)\n",
    "df2 = df2.drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruce\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "poly = preprocessing.PolynomialFeatures(degree=5)\n",
    "index1=df2['returns'][df2['returns'].columns[0:500]].mean(1)\n",
    "index2=df2['returns'][df2['returns'].columns[500:1000]].mean(1)\n",
    "pb1 = df2['pb'][df2['pb'].columns[0:500]].mean(1)\n",
    "pb2 = df2['pb'][df2['pb'].columns[500:1000]].mean(1)\n",
    "marketcap1 = df2['market_cap'][df2['market_cap'].columns[0:500]].mean(1)\n",
    "marketcap2 = df2['market_cap'][df2['market_cap'].columns[500:1000]].mean(1)\n",
    "factors = df1\n",
    "factors = factors.join([pb1,pb2,marketcap1,marketcap2],how='left')\n",
    "factors = pd.DataFrame(poly.fit_transform(factors))\n",
    "factors = factors.shift(1)\n",
    "factors = factors.fillna(0)\n",
    "#x = factors.join(df2.shift(1).fillna(0),how='left')\n",
    "#x= factors\n",
    "#pca = decomposition.PCA()\n",
    "#x = pca.fit_transform(x)\n",
    "y1 = index1-df1['3M_R'].shift(1).fillna(0)/252\n",
    "y2 = index2-df1['3M_R'].shift(1).fillna(0)/252\n",
    "model1 = linear_model.ElasticNet()\n",
    "model2 = linear_model.ElasticNet()\n",
    "model1.fit(factors,y1)\n",
    "model2.fit(factors,y2)\n",
    "pred1 = model1.predict(factors)\n",
    "pred2 = model2.predict(factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9969595745173758 0.4090298313553256 0.9974882318510973 0.46248946226115034\n"
     ]
    }
   ],
   "source": [
    "print((y1/pred1).mean(),(y1/pred1).std(),(y2/pred2).mean(),(y2/pred2).std())\n",
    "#print((index1/(pred1+df1['3M_R'])).mean())#,(y1/pred1).std(),(y2/pred2).mean(),(y2/pred2).std())\n",
    "pickle.dump(model1,open('index1.p','wb'))\n",
    "pickle.dump(model2,open('index2.p','wb'))\n",
    "model1 = pickle.load(open('index1.p','rb'))\n",
    "model2 = pickle.load(open('index2.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Symbol,calculus,diff,simplify\n",
    "from sympy.solvers import solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruce\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\bruce\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "lam=[]\n",
    "sigma_a = index1.std()\n",
    "sigma_b = index2.std()\n",
    "rho = np.corrcoef(index1,index2)[0][1]\n",
    "for i in range(30,500):\n",
    "    transformed = factors.iloc[i-1]\n",
    "    r =df1['3M_R'].iloc[i-1]/252\n",
    "    ea = model1.predict(transformed.reshape(1,-1))+r\n",
    "    eb = model2.predict(transformed.reshape(1,-1))+r\n",
    "    sign_a = np.sign(ea)\n",
    "    sign_b = np.sign(eb)\n",
    "    ea = abs(ea)\n",
    "    eb = abs(eb)\n",
    "    \n",
    "    #x = Symbol('x')\n",
    "    #w=solve(((ea-eb)*(vara**2+(vara*varb*rho-2*vara**2)*x+(varb**2-vara*varb*rho)*x**2)+(ea+(eb-ea)*x)*(vara*varb*rho-2*vara**2+\n",
    "                                                                   #2*(varb**2-vara*varb*rho)*x)),x)\n",
    "    \n",
    "    #print((ea))/(index1.iloc[i]-df1['3M_R'].iloc[i-1])\n",
    "    #print((eb))/(index1.iloc[i]-df1['3M_R'].iloc[i-1])\n",
    "    #print(abs(ea-eb))\n",
    "    #print (max(w[0]))\n",
    "\n",
    "    #if max(w[0])>0:\n",
    "        #weight = max(w[0])\n",
    "    #else:\n",
    "        #weight = 1/2\n",
    "    \"\"\"\n",
    "    if abs(ea-eb)>1e-10:\n",
    "        lambda1=(0.5-eb-r)/(ea-eb)\n",
    "    else:\n",
    "        lambda1=1/2\n",
    "    lam.append(lambda1)\n",
    "    \"\"\"\n",
    "    weight=(sigma_b**2-eb/(ea-eb))/(2*(sigma_b-sigma_a*sigma_b*rho))\n",
    "    l.append((weight)*index1[i]+(1-weight)*index2[i])\n",
    "    \n",
    "    #print(lambda1*index1[i]+(1-lambda1)*index2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gx(x,sigma_a,sigma_b,rho):\n",
    "    vara=(sigma_a)**2\n",
    "    varb=(sigma_b)**2\n",
    "    return x*x*(sigma_a*sigma_a+sigma_b*sigma_b-2*rho*sigma_a*sigma_b)+2*x*((rho*sigma_a*sigma_b)-sigma_b*sigma_b)+sigma_b*sigma_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gx_p(x,sigma_a,sigma_b,rho):\n",
    "    vara=(sigma_a)**2\n",
    "    varb=(sigma_b)**2\n",
    "    return 2*x*(sigma_a*sigma_a+sigma_b*sigma_b-2*rho*sigma_a*sigma_b)+2*((rho*sigma_a*sigma_b)-sigma_b*sigma_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_x(ea,eb,rho,sigma_a,sigma_b):\n",
    "    vara=(sigma_a)**2\n",
    "    varb=(sigma_b)**2\n",
    "    return (ea*(-varb)+eb*(rho*sigma_a*sigma_b))/(2*ea*(rho*sigma_a*sigma_b-varb)+eb*(-vara+varb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42461538461538506"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ea=0.2\n",
    "eb=0.5\n",
    "rho=0.2\n",
    "sigma_a=0.2\n",
    "sigma_b=0.5\n",
    "x=give_x(ea,eb,rho,sigma_a,sigma_b)\n",
    "(ea-eb)*2*gx(x,sigma_a,sigma_b,rho)- gx_p(x,sigma_a,sigma_b,rho)*((ea-eb)*x+eb)\n",
    "#(ea-eb)*(2*gx(x,sigma_a,sigma_b,rho)- x*gx_p(x,sigma_a,sigma_b,rho))-eb*gx_p(x,sigma_a,sigma_b,rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.672281126594081\n",
      "281.8003870051439\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(l))\n",
    "print(np.std(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.00009\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(252)*np.mean(l)/pd.DataFrame(a).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from portfolio import PortfolioGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, linear_model\n",
    "import pickle\n",
    "from sympy import Symbol,calculus,diff,simplify\n",
    "from sympy.solvers import solve\n",
    "\n",
    "\n",
    "weights = pd.read_csv('weights.csv')\n",
    "feature_coefs = pd.read_csv('feature_coefs.csv')\n",
    "index1_coefs = pd.read_csv('index1.csv')\n",
    "index2_coefs = pd.read_csv('index2.csv')\n",
    "index1_coefs= index1_coefs.drop('Unnamed: 0',axis=1)\n",
    "index2_coefs= index2_coefs.drop('Unnamed: 0',axis=1)\n",
    "model1 = pickle.load(open('index1.p','rb'))\n",
    "model2 = pickle.load(open('index2.p','rb'))\n",
    "\n",
    "class SampleStrategy(PortfolioGenerator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def build_signal(self, stock_features):\n",
    "        return self.momentum(stock_features)\n",
    "\n",
    "    def momentum(self, stock_features):\n",
    "        #estimating the big_ix Small_ix and rf\n",
    "        poly = preprocessing.PolynomialFeatures(5)\n",
    "        transformed_features =stock_features[['VIX', 'COPP','3M_R', 'US_TRY', 'BIG_IX', 'SMALL_IX', 'SENTI', 'TEMP', 'RAIN', 'OIL']].iloc[-1].reshape(1, -1)\n",
    "        transformed_features= np.append(transformed_features,stock_features['pb'][-1000:-500].mean())\n",
    "        transformed_features=np.append(transformed_features,stock_features['pb'][-500:].mean())\n",
    "        transformed_features=np.append(transformed_features,stock_features['market_cap'][-1000:-500].mean())\n",
    "        transformed_features=np.append(transformed_features,stock_features['market_cap'][-500:].mean())\n",
    "        #0.20015496989867212\n",
    "\n",
    "        transformed_features = pd.DataFrame(poly.fit_transform(transformed_features.reshape(1,-1)))\n",
    "        transformed_features = transformed_features.fillna(0)\n",
    "        vara =0\n",
    "        varb =0\n",
    "        for i in range(0,500):\n",
    "            vara+=(49)*stock_features.groupby(['ticker'])['returns'].var()[i]\n",
    "            varb+=(49)*stock_features.groupby(['ticker'])['returns'].var()[i+500]\n",
    "        vara=np.sqrt(vara/(49*500))\n",
    "        varb=np.sqrt(varb/(49*500))\n",
    "        rho = 0.20015496989867212\n",
    "\n",
    "        #print(index1_coefs.shape)\n",
    "        ea = model1.predict(transformed_features)+stock_features['3M_R'].iloc[-1]/252\n",
    "        eb = model2.predict(transformed_features)+stock_features['3M_R'].iloc[-1]/252\n",
    "        sign_a = np.sign(ea)\n",
    "        sign_b = np.sign(eb)\n",
    "        ea = abs(ea)\n",
    "        eb = abs(eb)\n",
    "        x = Symbol('x',real=True)\n",
    "        w = solve(((ea - eb) * (\n",
    "            vara ** 2 + (vara * varb * rho - 2 * vara ** 2) * x + (varb ** 2 - vara * varb * rho) * x ** 2) + (\n",
    "                   ea + (eb - ea) * x) * (vara * varb * rho - 2 * vara ** 2 +\n",
    "                                          2 * (varb ** 2 - vara * varb * rho) * x)), x)\n",
    "\n",
    "\n",
    "        if w:\n",
    "            if min(w[0][0],w[1][0])>0:\n",
    "                weight = min(w[0][0],[1][0])\n",
    "            elif max(w[0][0],w[1][0])>0:\n",
    "                weight = max(w[0][0],w[1][0])\n",
    "        else:\n",
    "            weight = .5\n",
    "\n",
    "        a = [sign_a*(1-weight)/500 for i in range(0,500)]\n",
    "        b = [sign_b*weight/500 for i in range(0,500)]\n",
    "        return np.append(a,b)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    portfolio = SampleStrategy()\n",
    "    sharpe = portfolio.simulate_portfolio()\n",
    "    print(\"*** Strategy Sharpe is {} ***\".format(sharpe))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
