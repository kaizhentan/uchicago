{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame([1,4,3,2,5,2,3,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.040285\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(data.loc[:3].std()-data.std())/data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]=[2,3,4,5,2,4,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.040285\n",
       "1    0.138550\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(data.loc[:3].std()-data.std())/data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from portfolio import PortfolioGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.read_csv('weights.csv')\n",
    "feature_coefs = pd.read_csv('feature_coefs.csv')\n",
    "index1_coefs = pd.read_csv('index1.csv')\n",
    "index2_coefs = pd.read_csv('index2.csv')\n",
    "index1_coefs= index1_coefs.drop('Unnamed: 0',axis=1)\n",
    "index2_coefs= index2_coefs.drop('Unnamed: 0',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LOOKBACK = 50\n",
    "\n",
    "class PortfolioGenerator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def read_stock_data(self):\n",
    "        '''\n",
    "        Description:\n",
    "            Reads in simulated stock data from stock_data.csv\n",
    "        Returns:\n",
    "            stock_df (DataFrame): standardized ticker/factor data in pandas df\n",
    "        Raises:\n",
    "            AssertionError: ticker_data.csv/factor_data.csv has an invalid format\n",
    "        '''\n",
    "        ticker_df = pd.read_csv('stock_data/ticker_data.csv')\n",
    "        factor_df = pd.read_csv('stock_data/factor_data.csv')\n",
    "        assert 'timestep' in ticker_df.columns, \"ticker_data.csv has an invalid format\"\n",
    "        assert 'ticker' in ticker_df.columns, \"ticker_data.csv has an invalid format\"\n",
    "        assert 'returns' in ticker_df.columns, \"ticker_data.csv has an invalid format\"\n",
    "        assert 'timestep' in factor_df.columns, \"factor_data.csv has an invalid format\"\n",
    "        ticker_df.set_index('timestep', inplace=True)\n",
    "        factor_df.set_index('timestep', inplace=True)\n",
    "        stock_df = ticker_df.join(factor_df, how='left')\n",
    "        return stock_df\n",
    "\n",
    "    def build_signal(self, stock_features):\n",
    "        '''\n",
    "        Description:\n",
    "            Using stock features, generate a buy/sell stock\n",
    "            signal (suggested from -100 to 100 where -100 is strong\n",
    "            sell signal) for the stock on a given day.\n",
    "        Args:\n",
    "            hist_features (DataFrame) - dataframe of historical features\n",
    "        Return:\n",
    "            signal (pandas Series) - key = ticker, value = signal\n",
    "        Raises:\n",
    "            NotImplementedError - throws error if the function is not implemented\n",
    "        '''\n",
    "        raise NotImplementedError(\"build_signal must be implemented\")\n",
    "\n",
    "    def simulate_portfolio(self):\n",
    "        '''\n",
    "        Description:\n",
    "            Simulates performance of the portfolio on historical data\n",
    "        Return:\n",
    "            sharpe (int) - sharpe ratio for the portfolio\n",
    "        '''\n",
    "        daily_returns = []\n",
    "        stock_df = self.read_stock_data()\n",
    "        for idx in stock_df.index.unique():\n",
    "            print(\"timestep\", idx)\n",
    "            if idx < MAX_LOOKBACK:\n",
    "                continue\n",
    "            stock_features = stock_df.loc[idx-MAX_LOOKBACK:idx-1]\n",
    "            returns = stock_df.loc[idx:idx].set_index('ticker')['returns']\n",
    "            signal = self.build_signal(stock_features)\n",
    "            signal_return = returns *signal\n",
    "            daily_returns.append(np.mean(signal_return))\n",
    "            #print(daily_returns[idx-50])\n",
    "        sharpe_ratio = np.sqrt(252) * (np.mean(daily_returns) / np.std(daily_returns))\n",
    "        #pd.DataFrame(daily_returns,columns=['a']).to_csv('dailyreturn_market.csv')\n",
    "        \n",
    "        return sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep 0\n",
      "timestep 1\n",
      "timestep 2\n",
      "timestep 3\n",
      "timestep 4\n",
      "timestep 5\n",
      "timestep 6\n",
      "timestep 7\n",
      "timestep 8\n",
      "timestep 9\n",
      "timestep 10\n",
      "timestep 11\n",
      "timestep 12\n",
      "timestep 13\n",
      "timestep 14\n",
      "timestep 15\n",
      "timestep 16\n",
      "timestep 17\n",
      "timestep 18\n",
      "timestep 19\n",
      "timestep 20\n",
      "timestep 21\n",
      "timestep 22\n",
      "timestep 23\n",
      "timestep 24\n",
      "timestep 25\n",
      "timestep 26\n",
      "timestep 27\n",
      "timestep 28\n",
      "timestep 29\n",
      "timestep 30\n",
      "timestep 31\n",
      "timestep 32\n",
      "timestep 33\n",
      "timestep 34\n",
      "timestep 35\n",
      "timestep 36\n",
      "timestep 37\n",
      "timestep 38\n",
      "timestep 39\n",
      "timestep 40\n",
      "timestep 41\n",
      "timestep 42\n",
      "timestep 43\n",
      "timestep 44\n",
      "timestep 45\n",
      "timestep 46\n",
      "timestep 47\n",
      "timestep 48\n",
      "timestep 49\n",
      "timestep 50\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 51\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 52\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 53\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 54\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruce\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\bruce\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "timestep 56\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 57\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 58\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 59\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 60\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 61\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 62\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 63\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 64\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 65\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 66\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 67\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 68\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 69\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 70\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 71\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 72\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 73\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 74\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 75\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 76\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 77\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 78\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 79\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 80\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 81\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 82\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 83\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 84\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 85\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 86\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 87\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 88\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 89\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 90\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 91\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 92\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 93\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 94\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 95\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 96\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 97\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 98\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 99\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 100\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 101\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 102\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 103\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 104\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 105\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 106\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 107\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 108\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 109\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 110\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 111\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 112\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 113\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 114\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 115\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 116\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 117\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 118\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 119\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 120\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 121\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 122\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 123\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 124\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 125\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 126\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 127\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 128\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 129\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 130\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 131\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 132\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 133\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 134\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 135\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 136\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 137\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 138\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 139\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 140\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 141\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 142\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 143\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 144\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 145\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 146\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 147\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 148\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 149\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 150\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 151\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 152\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 153\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 154\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 155\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 156\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 157\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 158\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 159\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 160\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 161\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 162\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 163\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 164\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 165\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 166\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 167\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 168\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 169\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 170\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 171\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 172\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 173\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 174\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 175\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 176\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 177\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 178\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 179\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 180\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 181\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 182\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 183\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 184\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 185\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 186\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 187\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 188\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 189\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 190\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 191\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 192\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 193\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 194\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 195\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 196\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 197\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 198\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 199\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 200\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 201\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 202\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 203\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 204\n",
      "<class 'numpy.ndarray'>\n",
      "timestep 205\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-3020dd36bdf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mportfolio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSampleStrategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0msharpe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mportfolio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulate_portfolio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"*** Strategy Sharpe is {} ***\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msharpe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-0b1f7793d4d2>\u001b[0m in \u001b[0;36msimulate_portfolio\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mstock_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstock_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mMAX_LOOKBACK\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mreturns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstock_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ticker'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'returns'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0msignal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_signal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[0msignal_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturns\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdaily_returns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal_return\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-3020dd36bdf0>\u001b[0m in \u001b[0;36mbuild_signal\u001b[1;34m(self, stock_features)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild_signal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstock_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstock_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-3020dd36bdf0>\u001b[0m in \u001b[0;36mmomentum\u001b[1;34m(self, stock_features)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m#estimating the big_ix Small_ix and rf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mpoly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPolynomialFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mtransformed_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'VIX'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'COPP'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'3M_R'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'US_TRY'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'BIG_IX'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SMALL_IX'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SENTI'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TEMP'\u001b[0m\u001b[1;33m,\u001b[0m       \u001b[1;34m'RAIN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'OIL'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mtransformed_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformed_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m#print(transformed_features.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1344\u001b[0m                                           self.include_bias)\n\u001b[0;32m   1345\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1346\u001b[1;33m             \u001b[0mXP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mXP\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "class SampleStrategy(PortfolioGenerator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def build_signal(self, stock_features):\n",
    "        return self.momentum(stock_features)\n",
    "\n",
    "    def momentum(self, stock_features):\n",
    "        #estimating the big_ix Small_ix and rf\n",
    "        poly = preprocessing.PolynomialFeatures(4)\n",
    "        transformed_features = pd.DataFrame(poly.fit_transform(stock_features[['VIX','COPP','3M_R', 'US_TRY','BIG_IX','SMALL_IX', 'SENTI','TEMP',\t'RAIN',\t'OIL']].iloc[-1].reshape(1,-1)))\n",
    "        transformed_features = transformed_features.fillna(0)\n",
    "        #print(transformed_features.shape)\n",
    "        #print(index1_coefs.shape)\n",
    "        ea = model1.predict(transformed_features)+stock_features['3M_R'].iloc[-1]\n",
    "        eb = model2.predict(transformed_features)+stock_features['3M_R'].iloc[-1]\n",
    "        #print(index1,index2)\n",
    "        #ea=my_predict[0]   \n",
    "        #eb=my_predict[1]\n",
    "        #print(ea)\n",
    "        if abs(ea-eb)>1e-10:\n",
    "            lambda1=(0.11-eb)/(ea-eb)\n",
    "        else:\n",
    "            lambda1=1/2\n",
    "        my_weights=np.zeros(1000)\n",
    "        my_weights[:500]=lambda1\n",
    "        my_weights[500:]=(1-lambda1)\n",
    "        #print(type(stock_features[['VIX','COPP','3M_R', 'US_TRY','BIG_IX','SMALL_IX', 'SENTI','TEMP',\t'RAIN',\t'OIL']].iloc[-1].reshape(1,-1)))\n",
    "        return my_weights\n",
    "        #return 1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    portfolio = SampleStrategy()\n",
    "    sharpe = portfolio.simulate_portfolio()\n",
    "    print(\"*** Strategy Sharpe is {} ***\".format(sharpe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_returns(features):\n",
    "        poly = preprocessing.PolynomialFeatures(4)\n",
    "        transformed_features = pd.DataFrame(poly.fit_transform(features))\n",
    "        transformed_features = transformed_features.fillna(0)\n",
    "        #print(transformed_features.shape)\n",
    "        #print(index1_coefs.shape)\n",
    "        index1 = np.dot(transformed_features,index1_coefs)[0]+stock_features['3M_R'].iloc[-1]\n",
    "        index2 = np.dot(transformed_features,index2_coefs)[0]+stock_features['3M_R'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruce\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\bruce\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, feature_selection,ensemble, linear_model, cross_validation, decomposition, cluster,model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruce\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\bruce\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame.from_csv('stock_data/factor_data.csv',index_col=10)\n",
    "df2 = pd.DataFrame.from_csv('stock_data/ticker_data.csv',index_col=['timestep','ticker'])\n",
    "df2 = df2.unstack()\n",
    "df2 = df2.fillna(0)\n",
    "clean_upcols = {'industry':{'TECH':0,'AGRICULTURE':1,'FINANCE':2,'CONSUMER':3,'OTHER':4}}\n",
    "df2.replace(clean_upcols,inplace=True)\n",
    "df2 = df2.drop(['index'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index1=df2['returns'].loc[:,:500].mean(1)\n",
    "index2=df2['returns'].loc[:,500:].mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruce\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9996886225667847 0.9996891806217687\n"
     ]
    }
   ],
   "source": [
    "poly = preprocessing.PolynomialFeatures(degree=4)\n",
    "factors = pd.DataFrame(poly.fit_transform(df1))\n",
    "factors = factors.shift(1)\n",
    "factors = factors.fillna(0)\n",
    "x = factors\n",
    "y1 = index1-df1['3M_R'].shift(1).fillna(method='bfill')\n",
    "y2 = index2-df1['3M_R'].shift(1).fillna(method='bfill')\n",
    "model1 = linear_model.ElasticNet()\n",
    "model2 = linear_model.ElasticNet()\n",
    "model1.fit(x,y1)\n",
    "model2.fit(x,y2)\n",
    "pred1 = model1.predict(x)\n",
    "pred2 = model2.predict(x)\n",
    "print((y1/pred1).mean(),(y2/pred2).mean())\n",
    "#index1_coefs = model.coef_\n",
    "pickle.dump(model1,open('index1.p','wb'))\n",
    "pickle.dump(model2,open('index2.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = pickle.load(open('index1.p','rb'))\n",
    "model2 = pickle.load(open('index2.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[0]['3M_R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-35-b4f1e1d75561>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-35-b4f1e1d75561>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    transformed_features= transformed_features.fillna(0)\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "for i in range(50,300):\n",
    "    poly = preprocessing.PolynomialFeatures(4)\n",
    "    transformed_features = pd.DataFrame(poly.fit_transform(np.array(df1.loc[i]))\n",
    "    transformed_features = transformed_features.fillna(0)\n",
    "    #print(my_predict)\n",
    "    ea = model1.predict(transformed_features)+df1.loc[i]['3M_R']\n",
    "    eb = model2.predict(transformed_features)+df1.loc[i]['3M_R']\n",
    "    #print(ea)\n",
    "    if abs(ea-eb)>1e-10:\n",
    "        lambda1=(5e-2-eb)/(ea-eb)\n",
    "    else:\n",
    "        lambda1=1/2\n",
    "    l.append(lambda1*index1[i+1]+(1-lambda1)*index2[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(252)*pd.DataFrame(l).mean()/pd.DataFrame(l).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
